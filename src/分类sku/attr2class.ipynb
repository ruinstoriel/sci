{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "7783786bd438721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:45:06.362023Z",
     "start_time": "2025-01-09T19:45:05.183920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2499,) (2499, 166)\n",
      "0.9983993597438976\n",
      "0.8502581755593803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  1010010001       0.78      0.88      0.82         8\n",
      "  1010010002       0.50      1.00      0.67         1\n",
      "  1010010003       1.00      1.00      1.00         2\n",
      "  1010020001       0.83      0.71      0.77         7\n",
      "  1010020002       0.75      1.00      0.86         3\n",
      "  1010020003       1.00      1.00      1.00         2\n",
      "  1010150001       1.00      0.75      0.86         8\n",
      "  1010150002       0.50      0.75      0.60         4\n",
      "  1010150003       0.00      0.00      0.00         0\n",
      "  1020010004       1.00      0.83      0.91         6\n",
      "  1020010005       1.00      1.00      1.00         6\n",
      "  1020010006       1.00      1.00      1.00         4\n",
      "  1020020004       1.00      1.00      1.00         2\n",
      "  1020020005       1.00      1.00      1.00         5\n",
      "  1020020006       0.86      1.00      0.92         6\n",
      "  1020150004       0.00      0.00      0.00         0\n",
      "  1020150005       1.00      0.91      0.95        11\n",
      "  1020150006       1.00      1.00      1.00         6\n",
      "  1030010007       1.00      0.81      0.89        21\n",
      "  1030010008       0.00      0.00      0.00         0\n",
      "  1030010009       0.50      0.50      0.50         2\n",
      "  1030010010       0.83      1.00      0.91         5\n",
      "  1030020007       1.00      0.94      0.97        18\n",
      "  1030020008       1.00      1.00      1.00         1\n",
      "  1030020009       0.00      0.00      0.00         0\n",
      "  1030020010       0.75      1.00      0.86         3\n",
      "  1030150007       1.00      1.00      1.00        24\n",
      "  1030150010       1.00      1.00      1.00         3\n",
      "  1040010011       0.89      0.73      0.80        11\n",
      "  1040010012       0.87      0.90      0.89        30\n",
      "  1040010013       1.00      1.00      1.00         8\n",
      "  1040020011       0.80      0.89      0.84         9\n",
      "  1040020012       0.94      0.91      0.92        32\n",
      "  1040020013       0.67      0.67      0.67         6\n",
      "  1040030012       0.00      0.00      0.00         1\n",
      "  1040150011       1.00      0.88      0.93         8\n",
      "  1040150012       0.91      0.91      0.91        32\n",
      "  1040150013       1.00      1.00      1.00         6\n",
      "  1050010014       0.00      0.00      0.00         0\n",
      "  1050010015       0.00      0.00      0.00         0\n",
      "  1050020014       0.00      0.00      0.00         0\n",
      "  1050020015       0.00      0.00      0.00         0\n",
      "  1050150014       0.00      0.00      0.00         0\n",
      "  1050150015       1.00      1.00      1.00         1\n",
      "  1070010017       1.00      1.00      1.00         7\n",
      "  1070010109       0.00      0.00      0.00         0\n",
      "  1070020017       1.00      1.00      1.00         5\n",
      "  1070020109       1.00      1.00      1.00         1\n",
      "  1070150017       0.00      0.00      0.00         0\n",
      "  1070150109       0.00      0.00      0.00         0\n",
      "  1080010018       1.00      1.00      1.00         1\n",
      "  1080010019       0.89      0.94      0.92        18\n",
      "  1080010020       1.00      0.94      0.97        18\n",
      "  1080010021       0.62      0.83      0.71         6\n",
      "  1080020018       0.00      0.00      0.00         0\n",
      "  1080020019       0.95      0.95      0.95        21\n",
      "  1080020020       0.92      0.92      0.92        13\n",
      "  1080020021       0.50      0.33      0.40         3\n",
      "  1080030019       0.00      0.00      0.00         0\n",
      "  1080150018       1.00      1.00      1.00         2\n",
      "  1080150019       0.88      1.00      0.93        21\n",
      "  1080150020       0.73      1.00      0.84         8\n",
      "  1080150021       1.00      0.83      0.91         6\n",
      "  1100010016       1.00      0.86      0.92         7\n",
      "  1100020016       1.00      1.00      1.00         7\n",
      "  1100150016       1.00      1.00      1.00         7\n",
      "  1110010026       0.67      0.33      0.44         6\n",
      "  1110010027       0.00      0.00      0.00         0\n",
      "  1110020026       0.75      1.00      0.86         3\n",
      "  1110020027       0.00      0.00      0.00         0\n",
      "  1110150026       0.64      0.78      0.70         9\n",
      "  1110150027       0.00      0.00      0.00         0\n",
      "  1130010022       1.00      1.00      1.00         1\n",
      "  1130010023       1.00      1.00      1.00         6\n",
      "  1130010024       0.95      0.97      0.96        38\n",
      "  1130010025       1.00      0.75      0.86         4\n",
      "  1130020022       1.00      1.00      1.00         2\n",
      "  1130020023       1.00      1.00      1.00         6\n",
      "  1130020024       0.79      1.00      0.88        15\n",
      "  1130020025       0.75      1.00      0.86         3\n",
      "  1130150022       1.00      1.00      1.00         1\n",
      "  1130150023       1.00      1.00      1.00         6\n",
      "  1130150024       0.97      1.00      0.98        28\n",
      "  1130150025       1.00      0.75      0.86         4\n",
      "  2010650046       0.00      0.00      0.00         0\n",
      "  2012250042       0.00      0.00      0.00         0\n",
      "  2012250043       1.00      1.00      1.00         4\n",
      "  2012250044       0.00      0.00      0.00         0\n",
      "  2012250045       0.00      0.00      0.00         0\n",
      "  2020120107       1.00      1.00      1.00         5\n",
      "  2020300105       1.00      1.00      1.00         1\n",
      "  2020650028       0.00      0.00      0.00         0\n",
      "  2020650029       0.00      0.00      0.00         0\n",
      "  2020650030       0.00      0.00      0.00         0\n",
      "  2020650031       0.00      0.00      0.00         0\n",
      "  2020650032       0.00      0.00      0.00         0\n",
      "  2020650033       0.00      0.00      0.00         0\n",
      "  2020650034       1.00      0.80      0.89         5\n",
      "  2020650035       0.00      0.00      0.00         0\n",
      "  2020650036       0.00      0.00      0.00         0\n",
      "  2020650037       1.00      1.00      1.00         3\n",
      "  2020650038       0.00      0.00      0.00         0\n",
      "  2030180098       0.00      0.00      0.00         0\n",
      "  2030400091       1.00      0.92      0.96        12\n",
      "  2030400099       1.00      1.00      1.00        14\n",
      "  2032250092       1.00      1.00      1.00         4\n",
      "  2032250093       1.00      0.92      0.96        12\n",
      "  2032250094       0.57      1.00      0.73         4\n",
      "  2032250095       0.00      0.00      0.00         0\n",
      "  2032250096       1.00      1.00      1.00         8\n",
      "  2032250097       0.00      0.00      0.00         0\n",
      "  2032250106       0.00      0.00      0.00         0\n",
      "  2040100059       0.00      0.00      0.00         0\n",
      "  2040180058       0.00      0.00      0.00         0\n",
      "  2040200041       0.00      0.00      0.00         0\n",
      "  2040400048       1.00      1.00      1.00        17\n",
      "  2040400050       1.00      1.00      1.00         2\n",
      "  2040400052       0.82      1.00      0.90         9\n",
      "  2040400054       1.00      1.00      1.00         5\n",
      "  2040400055       0.00      0.00      0.00         0\n",
      "  2040400057       0.00      0.00      0.00         0\n",
      "  2040400061       1.00      1.00      1.00         2\n",
      "  2042250039       1.00      1.00      1.00        12\n",
      "  2042250040       1.00      1.00      1.00        10\n",
      "  2042250041       0.00      0.00      0.00         0\n",
      "  2042250047       0.00      0.00      0.00         0\n",
      "  2042250049       0.00      0.00      0.00         0\n",
      "  2042250051       0.00      0.00      0.00         2\n",
      "  2042250053       1.00      1.00      1.00         4\n",
      "  2042250056       1.00      0.75      0.86         4\n",
      "  2042250060       1.00      0.80      0.89         5\n",
      "  2042250090       1.00      1.00      1.00        15\n",
      "  2070100108       0.88      1.00      0.93         7\n",
      "  2080100073       0.00      0.00      0.00         0\n",
      "  2080180068       0.00      0.00      0.00         0\n",
      "  2080180069       0.00      0.00      0.00         0\n",
      "  2080650067       0.80      0.80      0.80         5\n",
      "  2082250063       0.00      0.00      0.00         0\n",
      "  2082250064       0.84      1.00      0.92        27\n",
      "  2082250065       1.00      0.67      0.80        15\n",
      "  2082250066       0.00      0.00      0.00         0\n",
      "  2082250070       0.00      0.00      0.00         0\n",
      "  2082250071       0.80      1.00      0.89         4\n",
      "  2082250072       0.88      0.94      0.91        16\n",
      "  2100650062       1.00      1.00      1.00         6\n",
      "  2100650100       0.00      0.00      0.00         0\n",
      "  2110250076       1.00      1.00      1.00         5\n",
      "  2112250074       1.00      1.00      1.00         6\n",
      "  2112250075       0.00      0.00      0.00         0\n",
      "  2120200078       0.00      0.00      0.00         0\n",
      "  2120300077       0.95      1.00      0.98        20\n",
      "  2130100088       0.00      0.00      0.00         0\n",
      "  2130200085       0.00      0.00      0.00         0\n",
      "  2130650084       0.50      1.00      0.67         1\n",
      "  2130650086       1.00      0.80      0.89         5\n",
      "  2132250079       0.89      1.00      0.94        16\n",
      "  2132250080       1.00      1.00      1.00        12\n",
      "  2132250081       1.00      1.00      1.00        11\n",
      "  2132250082       1.00      1.00      1.00         8\n",
      "  2132250083       1.00      0.60      0.75         5\n",
      "  2132250087       1.00      1.00      1.00         6\n",
      "  2132250089       1.00      0.95      0.98        22\n",
      "  2140300101       0.00      0.00      0.00         0\n",
      "  2140450104       0.00      0.00      0.00         0\n",
      "  2140650103       0.00      0.00      0.00         0\n",
      "  2142250102       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.93      0.92       941\n",
      "   macro avg       0.59      0.60      0.59       941\n",
      "weighted avg       0.93      0.93      0.92       941\n",
      " samples avg       0.93      0.94      0.93       941\n",
      "\n",
      "Product Name: 3星线【c-c】25W双C线【2米线】 -> Predicted Codes: 1110020026, 2110250076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\s\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\miniconda3\\envs\\s\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\miniconda3\\envs\\s\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\miniconda3\\envs\\s\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import  HashingVectorizer\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import jieba\n",
    "import re\n",
    "# 初始化参数\n",
    "df = pd.read_excel('demo.xlsx',sheet_name='demo',usecols=[0,1])\n",
    "meta = pd.read_excel('demo.xlsx',sheet_name='meta',usecols=[0,1],dtype=str)\n",
    "\n",
    "# code  = pd.read_excel('D:\\python\\pytorch-learn\\code.xlsx',sheet_name='基础编码',usecols=[0,1,2,3,4])\n",
    "df['code'] = df['code'].apply(lambda x: x.split('-'))\n",
    "all_labels = [item for sublist in df['code'] for item in sublist]\n",
    "label_counts = Counter(all_labels)\n",
    "rare_labels = {label for label, count in label_counts.items() if count == 1}\n",
    "jieba.add_word(\"1.5米\")\n",
    "jieba.add_word(\"1米\")\n",
    "jieba.add_word(\"2米\")\n",
    "jieba.add_word(\"1.8米\")\n",
    "jieba.add_word(\"线\")\n",
    "jieba.add_word(\"100w\")\n",
    "jieba.add_word(\"88w\")\n",
    "jieba.add_word(\"66w\")\n",
    "jieba.add_word(\"67w\")\n",
    "jieba.add_word(\"80w\")\n",
    "jieba.add_word(\"200w\")\n",
    "jieba.add_word(\"60w\")\n",
    "jieba.add_word(\"45w\")\n",
    "jieba.add_word(\"cc\")\n",
    "jieba.add_word(\"120w\")\n",
    "jieba.add_word(\"88w\")\n",
    "jieba.add_word(\"荣max\")\n",
    "jieba.add_word(\"荣\")\n",
    "jieba.add_word(\"max\")\n",
    "jieba.add_word(\"30w\")\n",
    "jieba.add_word(\"65w\")\n",
    "jieba.add_word(\"op\")\n",
    "jieba.add_word(\"oppo\")\n",
    "jieba.add_word(\"mi\")\n",
    "jieba.add_word(\"mini\")\n",
    "jieba.add_word(\"mirco\")\n",
    "jieba.add_word(\"vo\")\n",
    "jieba.add_word(\"v\")\n",
    "jieba.add_word(\"240w\")\n",
    "jieba.add_word(\"pro\")\n",
    "#  '14' '15' '150' '150w' '1516' '16' '18w' '1米' '2' '200w' '20w' '22.5' '240w' '25w' '29w' '29wtypec' '2a' '2米' '3' '30w' '33w' '35w' '4' '40w'\n",
    "jieba.add_word(\"150w\")\n",
    "jieba.add_word(\"22.5w\")\n",
    "jieba.add_word(\"18w\")\n",
    "jieba.add_word(\"30w\")\n",
    "jieba.add_word(\"33w\")\n",
    "jieba.add_word(\"35w\")\n",
    "jieba.add_word(\"40w\")\n",
    "jieba.add_word(\"29w\")\n",
    "jieba.add_word(\"typec\")\n",
    "jieba.add_word(\"tpc\")\n",
    "jieba.add_word(\"大壳头\")\n",
    "jieba.add_word(\"头\")\n",
    "jieba.add_word(\"10a\")\n",
    "jieba.add_word(\"6a\")\n",
    "jieba.add_word(\"5a\")\n",
    "jieba.add_word(\"85w\")\n",
    "jieba.add_word(\"max\")\n",
    "jieba.add_word(\"usb\")\n",
    "jieba.add_word(\"d\")\n",
    "jieba.add_word(\"g\")\n",
    "jieba.add_word(\"plus\")\n",
    "jieba.add_word(\"18w\")\n",
    "jieba.add_word(\"12w\")\n",
    "jieba.add_word(\"55w\")\n",
    "jieba.add_word(\"90w\")\n",
    "jieba.add_word(\"55w\")\n",
    "jieba.add_word(\"44w\")\n",
    "jieba.add_word(\"10w\")\n",
    "jieba.add_word(\"快充头\")\n",
    "jieba.add_word(\"快充\")\n",
    "jieba.add_word(\"闪充头\")\n",
    "jieba.add_word(\"闪充\")\n",
    "jieba.add_word(\"安卓线\")\n",
    "jieba.add_word(\"安卓\")\n",
    "jieba.add_word(\"华\")\n",
    "jieba.add_word(\"双口\")\n",
    "jieba.add_word(\"c口\")\n",
    "jieba.add_word(\"单口\")\n",
    "jieba.add_word(\"华为\",freq=0)\n",
    "jieba.add_word(\"ac\")\n",
    "jieba.add_word(\"vvivo\",freq=0)\n",
    "stop_words=[\"【\", \"】\", \"+\",\"（\",\"）\",\"(\",\")\",\" \",\"*\",\",\",\"/\",\"=\",\"|\"]\n",
    "#stop_words=[]\n",
    "def chinese_tokenizer(context):\n",
    "# 使用正则表达式去除自定义停止词\n",
    "    for stop_word in stop_words:\n",
    "        context = context.replace(stop_word, ' ')\n",
    "    context = context.replace('-', '')\n",
    "    context = context.replace('vivo', 'vvivo')\n",
    "    context = context.lower()\n",
    "    return list(jieba.cut(context))\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer=chinese_tokenizer,\n",
    "    token_pattern=None,\n",
    "    lowercase=True,\n",
    "    binary=False\n",
    ")\n",
    "\n",
    "md = MultiOutputClassifier(DecisionTreeClassifier(criterion=\"entropy\",random_state=42,max_depth=None,max_features=None))\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('clf', md)\n",
    "])\n",
    "\n",
    "\n",
    "# 创建一个新的 DataFrame 来保存稀有类别的样本\n",
    "df_rare = df[df['code'].apply(lambda x: any(item in rare_labels for item in x))]\n",
    "\n",
    "# 从原始 DataFrame 中移除这些稀有类别的样本\n",
    "df_common = df.drop(df_rare.index)\n",
    "mlb = MultiLabelBinarizer()\n",
    "meta['code'] = meta['code'].apply(lambda x:[x])\n",
    "mlb.fit(meta['code'])\n",
    "#mlb.fit(df_common['code'])\n",
    "Y_common = mlb.transform(df_common['code'])\n",
    "# 拆分常见类别的数据集\n",
    "X_train_common, X_test_common, Y_train_common, Y_test_common = train_test_split(\n",
    "    df_common['name'], Y_common, test_size=0.20, random_state=45\n",
    ")\n",
    "# 将稀有类别的样本添加到训练集中\n",
    "X_train_rare = df_rare['name']\n",
    "Y_train_rare = mlb.transform(df_rare['code'])\n",
    "# print(X_train_rare.shape, Y_train_rare.shape)\n",
    "# 合并训练集\n",
    "X_train = pd.concat([meta['name'],X_train_common, X_train_rare], ignore_index=True)\n",
    "Y_train = np.vstack([mlb.transform(meta['code']),Y_train_common, Y_train_rare])\n",
    "print(X_train.shape, Y_train.shape)\n",
    "# 测试集保持不变\n",
    "X_test = X_test_common\n",
    "Y_test = Y_test_common\n",
    "#print(mlb.classes_)\n",
    "pipeline.fit(X_train, Y_train)\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "print(pipeline.score(X_train, Y_train))\n",
    "print(pipeline.score(X_test, Y_test))\n",
    "\n",
    "# 打印特征名称（词汇表）\n",
    "# print(\"Feature names:\", vectorizer.get_feature_names_out())\n",
    "print(classification_report(Y_test, Y_pred, target_names=mlb.classes_))\n",
    "X_pre = [\"3星线【c-c】25W双C线【2米线】\"]\n",
    "n_pred = pipeline.predict(X_pre)\n",
    "predicted_codes = mlb.inverse_transform(n_pred)\n",
    "# print(cross_val_score(pipeline, X_train, Y_train, cv=5))\n",
    "for name, codes in zip(X_pre, predicted_codes):\n",
    "   print(f\"Product Name: {name} -> Predicted Codes: {', '.join(codes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93435717744bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b57eb376934b75a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T19:43:55.409976Z",
     "start_time": "2025-01-09T19:43:55.403958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['华为', '【', '66W', '快充', '快充头', '+', '2米', '米线', '】']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.add_word(\"华为\",freq=1)\n",
    "list(jieba.cut(\"华为【66W快充头+2米线】\",HMM=True,cut_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "522477ad846cf71f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T13:14:41.362460Z",
     "start_time": "2025-01-07T13:14:41.345134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     苹果 数据线 主推数据线苹果15编织线1.5米线(一条)\n",
      "1          华 数据线 主推数据线华为快充线1米线(一条)\n",
      "2          华 数据线 主推数据线华为快充线1米线(两条)\n",
      "3        华 数据线 主推数据线华为快充线1.5米线(一条)\n",
      "4    安卓 数据线 主推数据线安卓梯形micro线2米线(两条)\n",
      "Name: feature, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0005911994271138112),\n",
       " np.float64(0.00024186554835175925),\n",
       " np.float64(3.6901704552422166e-05),\n",
       " np.float64(0.02073848176224028))"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import jieba\n",
    "# 初始化参数\n",
    "df = pd.read_excel('demo.xlsx',sheet_name='demo',usecols=[0,1,2,3])\n",
    "\n",
    "df['code'] = df['code'].apply(lambda x: x.split(','))\n",
    "all_labels = [item for sublist in df['code'] for item in sublist]\n",
    "label_counts = Counter(all_labels)\n",
    "rare_labels = {label for label, count in label_counts.items() if count == 1}\n",
    "# 稀有类别对验证没有任何帮助，直接去除\n",
    "df['code'] = df['code'].apply(lambda x: np.unique( [item for item in x if item not in rare_labels]))\n",
    "# rare_labels,np.unique(df['code'].values)\n",
    "df = df[df['code'].apply(lambda x: len(x)>0)]\n",
    "# 构建特征, 使用l2进行归一化，smooth_idf 方式分母为0\n",
    "tf = TfidfVectorizer(norm=\"l2\",smooth_idf=True)\n",
    "df['feature'] = df[['series', 'type', 'name']].astype(str).apply(' '.join, axis=1)\n",
    "print(df['feature'].head(5))\n",
    "X = tf.fit_transform(df['feature'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y = mlb.fit_transform(df['code'])\n",
    "\n",
    "# 方差过滤\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_var = VarianceThreshold().fit_transform(X)\n",
    "\n",
    "\n",
    "# 方差太小，说明特征无效\n",
    "X_pd = pd.DataFrame(X.toarray())\n",
    "X_pd.var().mean(),X_pd.var().median(),X_pd.var().min(),X_pd.var().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c74621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.001927978523826236),\n",
       " np.float64(0.000798134963955713),\n",
       " np.float64(4.452107091598113e-05),\n",
       " np.float64(0.023728835386231224))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建特征, 使用l2进行归一化，smooth_idf 方式分母为0\n",
    "import jieba\n",
    "tf = TfidfVectorizer(norm=\"l2\",smooth_idf=True,analyzer=jieba.cut)\n",
    "X = tf.fit_transform(df['name'])\n",
    "\n",
    "\n",
    "\n",
    "# 方差过滤\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_var = VarianceThreshold().fit_transform(X)\n",
    "\n",
    "\n",
    "# 方差变大，说明区别明显了\n",
    "X_pd = pd.DataFrame(X.toarray())\n",
    "X_pd.var().mean(),X_pd.var().median(),X_pd.var().min(),X_pd.var().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f925fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.500 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.01752685805104584),\n",
       " np.float64(0.001810359126497556),\n",
       " np.float64(0.0002266545784224851),\n",
       " np.float64(0.49361364371154876))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试直接count， jieba 分词\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "stop=[\"【\", \"】\", \"+\",\"（\",\"）\",\"(\",\")\",\" \",\"*\",\",\",\"/\",\"=\",\"|\"]\n",
    "tf = CountVectorizer(analyzer=jieba.cut)\n",
    "X = tf.fit_transform(df['name'])\n",
    "\n",
    "\n",
    "\n",
    "# 方差过滤\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_var = VarianceThreshold().fit_transform(X)\n",
    "\n",
    "\n",
    "# 方差变大，说明区别明显了\n",
    "X_pd = pd.DataFrame(X.toarray())\n",
    "X_pd.var().mean(),X_pd.var().median(),X_pd.var().min(),X_pd.var().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "1786e20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8900606542733553)"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉验证\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 假设你有 X (特征), y (标签)\n",
    "skf = MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "md = MultiOutputClassifier(DecisionTreeClassifier(criterion=\"log_loss\",max_depth=10,random_state=42))\n",
    "\n",
    "# 使用 cross_val_score 并指定 scoring 参数 X_embedded X_var\n",
    "cross_val_score(md,X_embedded,y,cv=skf,scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试结果\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 假设你有 X (特征), y (标签)\n",
    "skf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "md = MultiOutputClassifier(DecisionTreeClassifier(criterion=\"log_loss\",splitter=\"random\"))\n",
    "\n",
    "demo_df = pd.read_excel(\"D:/work/采购/现实仓库/demo_.xlsx\",usecols=[\"商品简称\"])\n",
    "demo_df[\"商品简称\"] = demo_df[\"商品简称\"].str.replace(\"\\t\",\"\")\n",
    "\n",
    "md.fit(X_var,y)\n",
    "\n",
    "X_input = vectorizer.transform(demo_df[\"商品简称\"].values.ravel())\n",
    "n_pred = md.predict(X_input)\n",
    "predicted_codes = mlb.inverse_transform(n_pred)\n",
    "re = []\n",
    "for code in predicted_codes:\n",
    "    s = \",\".join(code)\n",
    "    re.append(s)\n",
    "demo_df['预测结果'] = re\n",
    "demo_df.to_excel(\"D:/work/采购/现实仓库/demo_.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b97e93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ' '.' '1' '1.5米' '1.8米' '10' '100' '100w' '10a' '10w' '11' '120' '120w'\n",
      " '12a' '12w' '14' '15' '150' '150w' '16' '168' '18w' '1米' '2' '200w' '20w'\n",
      " '22.5w' '240w' '25w' '29w' '2a' '2米' '3' '30w' '33' '33w' '35w' '3t' '3星'\n",
      " '3米' '4' '40' '40w' '44w' '45' '45w' '4a' '5' '55w' '5a' '5t' '5v2a'\n",
      " '5v4a' '6' '60w' '614' '61w' '65' '65w' '66' '66w' '67' '67w' '6a' '6t'\n",
      " '7' '8' '80' '80w' '814' '85w' '87w' '88' '88w' '8a' '9' '90' '90w'\n",
      " '91619' '96w' 'a' 'a1181' 'a1278' 'a1286' 'a1343' 'a1369' 'a1370' 'a1398'\n",
      " 'a14' 'a1424' 'a1425' 'a1465' 'a1502' 'a1534' 'a1706' 'a1707' 'a1708'\n",
      " 'a1932' 'a1990' 'a21' 'a2141' 'a2363' 'a2518' 'c' 'cc' 'cro' 'ctoc'\n",
      " 'ctoc口' 'c口' 'd' 'e' 'findx6' 'findx8' 'g' 'h' 'ic' 'ipad' 'iqoo' 'k10'\n",
      " 'k11' 'k11x' 'k20' 'k5' 'k50' 'k60' 'k7' 'k70' 'k80' 'k9' 'lightning'\n",
      " 'l型接口' 'magic6' 'max' 'mi' 'mini' 'mirco' 'note13' 'note7' 'op' 'pd'\n",
      " 'plus' 'pro' 'r9' 'reno10' 'reno11' 'reno12' 'reno9' 'to' 'tpc' 'typec'\n",
      " 'typec转typec' 't型接口' 'usb' 'usb口' 'v' 'v120' 'v33' 'v3380' 'vivo' 'vo'\n",
      " 'vooc' 'x20' 'x70' 'x70t' 'x9' '一' '一体' '一加' '三星' '主推' '充' '充电头' '全'\n",
      " '全兼容' '冲' '准' '加' '努比亚' '华' '单线' '原' '双' '双c' '双c口' '双口' '双口头' '双头' '双引擎'\n",
      " '嘉' '大壳' '大壳g' '大壳头g' '头' '安卓' '小' '小壳d' '小布丁' '小数点' '小米' '平板' '弯头' '扁口'\n",
      " '手机' '接口' '数据线' '标准版' '梯形' '正常' '版' '电源' '白' '白口' '白线' '直头' '笔记本' '米'\n",
      " '紫口' '红' '红线' '红色' '线' '绿口' '编织' '胶囊' '苹果' '荣' '荣max' '荣耀' '蓝标' '装' '足功率'\n",
      " '适用' '金标' '金标头' '金标头g' '金标线' '黄' '黄口' '黑' '黑头' '黑色' '黑鲨']\n"
     ]
    }
   ],
   "source": [
    "# 尝试直接count\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "# 尝试清理噪音 ,\"\",\"\"\n",
    "stop=[\"【\", \"】\", \"+\",\"（\",\"）\",\"(\",\")\",\"*\",\",\",\"/\",\"=\",\"|\",\";\",\"以上\",\"如果\",\"邮费\",\"\\t\",\"单条装\",\n",
    "      \"一条\",\"两条装\",\"其他\",\"，\",\"一个\",\"三条\",\"超级\",\"开盖\",\"公对公\",\"快充不伤机\",\"不含线\",\"2件\",\"4件\",\n",
    "      \"1条装\",\"2条装\",\"1条\",\"2条\",\"3条\",\"条\",\"两条\",\"单条\",\"没有\",\"光速\",\"加长\",\"充电器套装\",\"充电器\",\"显示\",\"是\",\"笔记本电脑\",\"优惠装\",\"搭配装\",\"优惠\",\"链接\",\"同长\",\"默认\",\"爆款\",\"秒\",\"备注\",\"品牌\"\n",
    "      ,\"发\",\"冲头\",\"两\",\"电竞版\",\"请\",\"充电数据线\",\"安卓快充电线\",\"快充电线\",\"充电线\",\"闪充线\",\"闪充数据线\",\"看后面\",\"后面\",\"普通\",\"单个头\",\"快充头\",\"快充线\",\"正品\",\"专用头\",\"专用\"\n",
    "      ,\"2个\",\"1个\",\"3个\",\"2根\",\"3根\",\"6根\",\"单个\",\"单头\",\"闪充头\",\"闪充\",\"快充\",\"线长\",\"通用\",\"极速\",\"系列\",\"适配器\",\"配\",\"套装\"]\n",
    "jieba.load_userdict(\"userdict.txt\")\n",
    "jieba.del_word(\"口红\")\n",
    "jieba.del_word(\"头套\")\n",
    "def chinese_tokenizer(context):\n",
    "    # 使用正则表达式去除自定义停止词\n",
    "    context = context.lower()\n",
    "    for stop_word in stop:\n",
    "        context = context.replace(stop_word, ' ')\n",
    "    context = context.replace('-', '')\n",
    "    context = context.replace('iapd', 'ipad')\n",
    "    context = context.replace('编制', '编织')\n",
    "    context = context.replace('华为', '华')\n",
    "    context = context.replace('平果', '苹果')\n",
    "    context = context.replace('viov', 'vo')\n",
    "    context = context.replace('vovi', 'vo')\n",
    "    context = context.replace('oppo', 'op')\n",
    "    context = context.replace('双tpc', '双c')\n",
    "    context = context.replace('双typec', '双c')\n",
    "    context = context.replace('绿口线', '绿口')\n",
    "    context = context.replace('紫口线', '紫口')\n",
    "    context = context.replace('白口线', '白口')\n",
    "    context = context.replace('tpc口', 'c口')\n",
    "    context = context.replace('白色', '白')\n",
    "    context = context.replace('白头', '白')\n",
    "    context = context.replace('小白', '白')\n",
    "    context = context.replace('看后面', '后面')\n",
    "    context = context.replace('米6a线', '6a')\n",
    "    context = context.replace('米6a', '6a')\n",
    "    context = context.replace('华总', '华')\n",
    "    context = context.replace('高攻', 'g')\n",
    "    context = context.replace('高功', 'g')\n",
    "    context = context.replace('高', 'g')\n",
    "    context = context.replace('sam星', '三星')\n",
    "    re =  list(jieba.cut(context,cut_all=False,HMM=False,use_paddle=True))\n",
    "    if any(word == \"鲨\" for word in re):\n",
    "        print(context)\n",
    "    return re\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer=chinese_tokenizer,\n",
    "    token_pattern=None,\n",
    "    lowercase=True,\n",
    "    binary=True\n",
    ")\n",
    "X = vectorizer.fit_transform(df['feature'])\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "# 方差过滤\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=0.97,svd_solver=\"full\")  # 降维到2维，白化\n",
    "\n",
    "# X_dr = pca.fit_transform(X.toarray())  # 训练\n",
    "# print(X_dr.shape)  # 降维后的数据\n",
    "# # 去除噪音\n",
    "# X = pca.inverse_transform(X_dr)  # 还原数据\n",
    "# print(X.shape)  # 还原后的数据\n",
    "\n",
    "X_var = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "27827944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4493, 241)\n",
      "(4493, 81) ['.' '1' '1.5米' '100w' '120w' '12w' '150' '150w' '18w' '1米' '200w' '240w'\n",
      " '25w' '29w' '2米' '30w' '33w' '40w' '44w' '45' '45w' '55w' '5a' '65w'\n",
      " '66w' '67w' '6a' '80w' '88w' '90w' 'a' 'c' 'cc' 'ctoc口' 'c口' 'd' 'g' 'ic'\n",
      " 'ipad' 'l型接口' 'max' 'mi' 'op' 'pd' 'typec' 't型接口' 'usb' 'vo' '一加' '三星'\n",
      " '主推' '充' '充电头' '全兼容' '加' '努比亚' '华' '双c' '双口' '双口头' '大壳头g' '头' '安卓' '小布丁'\n",
      " '小米' '弯头' '数据线' '白' '笔记本' '米' '紫口' '线' '绿口' '编织' '胶囊' '苹果' '荣' '荣max'\n",
      " '金标' '金标线' '黄口']\n"
     ]
    }
   ],
   "source": [
    "# 尝试嵌入法，下过变差了，threshold=0.0005 差不多，不能过大，缩减到96个特征  1/219 ,每个特征的重要性大概 0.005\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(X_var.shape)\n",
    "embedded_mode = SelectFromModel(DecisionTreeClassifier(criterion=\"entropy\"), threshold=0.0004)\n",
    "X_embedded = embedded_mode.fit_transform(X, y)\n",
    "print(X_embedded.shape,vectorizer.get_feature_names_out()[embedded_mode.get_support()])\n",
    "# X_embedded = VarianceThreshold().fit_transform(X_embedded)\n",
    "\n",
    "\n",
    "# 方差虽然变大了，但是特征少了\n",
    "# X_pd = pd.DataFrame(X_embedded.toarray())\n",
    "# X_pd.var().mean(),X_pd.var().median(),X_pd.var().min(),X_pd.var().max(),X_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "80675833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试包装法\n",
    "# 包装法 , 逻辑回归优先使用嵌入法，svm 优先使用包装法\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = DecisionTreeClassifier(criterion=\"entropy\",random_state=42)\n",
    "rfe = RFE(rfc, n_features_to_select=80)\n",
    "X_rfe = rfe.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca504317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries from D:\\ProgramData\\miniconda3\\envs\\p\\Lib\\site-packages\\cutword\\dict.txt\n",
      "Loading dictionaries from userdict.txt\n",
      "['华为', '主推', 'G']\n"
     ]
    }
   ],
   "source": [
    "import cutword\n",
    "\n",
    "import cutword\n",
    "\n",
    "cutter = cutword.Cutter(\n",
    "    custom_dict_path=\"userdict.txt\",\n",
    ")\n",
    "res = cutter.cutword(\"华为主推G\")\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b305e158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.str_('华66w双口头【A+C】-25w'), np.str_('华6a线-1米'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试结果\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "# 假设你有 X (特征), y (标签)\n",
    "skf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "md = MultiOutputClassifier(RandomForestClassifier(n_estimators=10,criterion=\"entropy\"))\n",
    "\n",
    "\n",
    "md.fit(X_var,y)\n",
    "\n",
    "X_input = vectorizer.transform([\"华66双口头【66W快充头+1米线】\"])\n",
    "n_pred = md.predict(X_input)\n",
    "predicted_codes = mlb.inverse_transform(n_pred)\n",
    "predicted_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "751b34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4493, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.bin']"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 持久化\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "# 假设你有 X (特征), y (标签)\n",
    "skf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "md = MultiOutputClassifier(DecisionTreeClassifier(criterion=\"log_loss\",max_depth=10))\n",
    "\n",
    "# X_embedded  X_var\n",
    "print(X_embedded.shape)\n",
    "md.fit(X_embedded,y)\n",
    "joblib.dump(md, \"model.bin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a02ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 242)\n",
      "(1, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(np.str_('华66w双口头【A+C】-25w'), np.str_('华6a线-1米'))]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "md = joblib.load(\"model.bin\")\n",
    "X_input = vectorizer.transform([\"华 充电头 数据线 华双口66w 充电头+1米线\"])\n",
    "print(X_input.shape)\n",
    "X_input = X_input[:,embedded_mode.get_support()]\n",
    "print(X_input.shape)\n",
    "n_pred = md.predict(X_input)\n",
    "predicted_codes = mlb.inverse_transform(n_pred)\n",
    "predicted_codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
